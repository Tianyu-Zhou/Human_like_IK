{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import pingouin as pg\n",
    "import plotly.express as px\n",
    "import seaborn as sns \n",
    "from statannot import add_stat_annotation\n",
    "import os\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from plotly.subplots import make_subplots\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SampEn(U, m, r):\n",
    "    \"\"\"\n",
    "    用于量化时间序列的可预测性\n",
    "    :param U: 时间序列\n",
    "    :param m: 模板向量维数\n",
    "    :param r: 距离容忍度，一般取0.1~0.25倍的时间序列标准差，也可以理解为相似度的度量阈值\n",
    "    :return: 返回一个-np.log(A/B)，该值越小预测难度越小\n",
    "    \"\"\"\n",
    "    def _maxdist(x_i, x_j):\n",
    "        \"\"\"\n",
    "         Chebyshev distance\n",
    "        :param x_i:\n",
    "        :param x_j:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        return max([abs(ua - va) for ua, va in zip(x_i, x_j)])\n",
    "\n",
    "    def _phi(m):\n",
    "        x = [[U[j] for j in range(i, i + m - 1 + 1)] for i in range(N - m + 1)]\n",
    "        C = [len([1 for j in range(len(x)) if i != j and _maxdist(x[i], x[j]) <= r]) for i in range(len(x))]\n",
    "        \n",
    "        return sum(C)\n",
    "\n",
    "    N = len(U)\n",
    "    if _phi(m) == 0:\n",
    "        return 0.2\n",
    "    else:\n",
    "        return -np.log(_phi(m + 1) / _phi(m))\n",
    "    \n",
    "m = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Read Data ###\n",
    "path = '../data/process/'\n",
    "local_name = locals()\n",
    "data_raw = []\n",
    "human_like_collision = []\n",
    "traditional_collision = []\n",
    "conditions = []\n",
    "\n",
    "collision_statistics = pd.DataFrame(columns = [\"collision_times\",\"conditions\",\"trail\",\"time\"])\n",
    "\n",
    "axis3 = ['X','Y','Z']\n",
    "# participant_id_order = [\"01\",\"02\",\"03\",\"04\",\"05\",\"06\",\"07\",\"08\",\"09\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\",\"21\",\"22\",\"23\",\"24\",\"25\",\"26\",\"27\",\"28\",\"29\",\"30\"]\n",
    "participant_id_order = [\"01\",\"02\",\"03\",\"04\",\"05\",\"06\",\"07\",\"08\",\"09\",\"10\"]\n",
    "trail_id_order = [\"01\",\"02\",\"03\",\"04\",\"05\",\"06\",\"07\",\"08\",\"09\",\"10\"]\n",
    "# you can add column name here to get the velocity and acceleration\n",
    "column_names = ['Joint8']\n",
    "groups_order = [\"human_like\",\"traditional\"]\n",
    "\n",
    "# 'valve_calculate = 0' means calculate the collision between the joints and valves\n",
    "# 'valve_calculate = 1' means only calculate the collision between the joints and pipe\n",
    "valve_calculate = 0\n",
    "\n",
    "### calculate entropy. Will cost a lot of time!!!!!\n",
    "calculate_entropy = 0\n",
    "\n",
    "if calculate_entropy:\n",
    "    for name in participant_id_order:\n",
    "        for group in groups_order:\n",
    "            for axis in axis3:\n",
    "                local_name[name  + '_' + group + '_pos_' + axis + '_entropy'] = []            \n",
    "                local_name[name  + '_' + group + '_vel_' + axis + '_entropy'] = []            \n",
    "                local_name[name  + '_' + group + '_vel_' + axis + '_mean'] = []            \n",
    "                local_name[name  + '_' + group + '_acc_' + axis + '_mean'] = []   \n",
    "\n",
    "for home, dirs, files in os.walk(path):\n",
    "    for filename in files:\n",
    "        each_collision = []\n",
    "        raw=pd.read_csv(home+\"/\"+filename,index_col=0)\n",
    "\n",
    "        ## get velocity and acceleration for 'column_names'\n",
    "        for column_name in column_names:\n",
    "            for axis in axis3:\n",
    "                local_name['vel_' + axis] = []\n",
    "                local_name['acc_' + axis] = []\n",
    "                local_name['p_' + axis + '_previous'] = 0\n",
    "                local_name['vel_' + axis + '_previous'] = 0\n",
    "\n",
    "                for i,local_name['p_' + axis] in raw[column_name + axis].iteritems():\n",
    "                    ## get vel by delta_p\n",
    "                    local_name['delta_p_' + axis] = local_name['p_' + axis] - local_name['p_' + axis + '_previous']\n",
    "                    if abs(local_name['delta_p_' + axis])>5.0:\n",
    "                        local_name['vel_' + axis].append(0)\n",
    "                    else:\n",
    "                        local_name['vel_' + axis].append(local_name['delta_p_' + axis])\n",
    "                    local_name['p_' + axis + '_previous'] = local_name['p_' + axis]\n",
    "\n",
    "                    ## get acc by delta_vel\n",
    "                    local_name['delta_vel_' + axis] = local_name['delta_p_' + axis] - local_name['vel_' + axis + '_previous']\n",
    "                    local_name['acc_' + axis].append(local_name['delta_vel_' + axis])\n",
    "                    local_name['vel_' + axis + '_previous'] = local_name['delta_p_' + axis]\n",
    "\n",
    "                raw[\"vel_\" + axis] = local_name['vel_' + axis]\n",
    "                raw[\"acc_\" + axis] = local_name['acc_' + axis]\n",
    "\n",
    "\n",
    "\n",
    "        # read the index of start button \"C\"\n",
    "        start_point = int(raw.apply(pd.Series.first_valid_index)[['StartSignal']].values[0])\n",
    "        # read the index of the mission complete time\n",
    "        last_point = int(raw.apply(pd.Series.last_valid_index)[['CollisionMissionTarget']].values[0])\n",
    "        t=raw[start_point:last_point]\n",
    "\n",
    "        if(filename[0:5] == \"human\"):\n",
    "            condition = \"human_like\"\n",
    "            conditions.append(condition)\n",
    "            participant_id = filename[15:17]\n",
    "            trail_id = filename[23:25]\n",
    "\n",
    "            # groupby collision position\n",
    "            human_like_group = t.groupby(['ColX', 'ColY', 'ColZ'])\n",
    "            if not valve_calculate:\n",
    "                for h,d in human_like_group:\n",
    "                    if (h[0] != 0.0):\n",
    "                        if d[[\"CollisionTarget\"]].values[0][0][0:4] != \"Miss\" and d[[\"CollisionTarget\"]].values[0][0][0:4] != \"Pipe\":\n",
    "                            human_like_collision.append(h)\n",
    "                            each_collision.append(h)\n",
    "            if valve_calculate:\n",
    "                for h,d in human_like_group:\n",
    "                    if (h[0] != 0.0):\n",
    "                        if not (d[[\"CollisionTarget\"]].values[0][0][0:4] == \"Miss\" and d[[\"CollisionJoint\"]].values[0][0][0:4] == \"node\"):\n",
    "                            human_like_collision.append(h)\n",
    "                            each_collision.append(h)\n",
    "            collision_statistics = collision_statistics.append({'collision_times': len(each_collision), 'conditions':condition, 'trail':trail_id, 'time':len(t)},ignore_index=True)\n",
    "\n",
    "        if(filename[0:5] == \"tradi\"):\n",
    "            condition = \"traditional\"\n",
    "            conditions.append(condition)\n",
    "            participant_id = filename[16:18]\n",
    "            trail_id = filename[24:26]\n",
    "            traditional_group = t.groupby(['ColX', 'ColY', 'ColZ'])\n",
    "            if not valve_calculate:\n",
    "                for h,d in traditional_group:\n",
    "                    if (h[0] != 0.0):\n",
    "                        if d[[\"CollisionTarget\"]].values[0][0][0:4] != \"Miss\" and d[[\"CollisionTarget\"]].values[0][0][0:4] != \"Pipe\":\n",
    "                            traditional_collision.append(h)\n",
    "                            each_collision.append(h)\n",
    "            if valve_calculate:\n",
    "                for h,d in traditional_group:\n",
    "                    if (h[0] != 0.0):\n",
    "                        if not (d[[\"CollisionTarget\"]].values[0][0][0:4] == \"Miss\" and d[[\"CollisionJoint\"]].values[0][0][0:4] == \"node\"):\n",
    "                            traditional_collision.append(h)\n",
    "                            each_collision.append(h)\n",
    "            collision_statistics = collision_statistics.append({'collision_times': len(each_collision), 'conditions':condition, 'trail':trail_id, 'time':len(t)},ignore_index=True)\n",
    "        data_raw.append(t)\n",
    "\n",
    "\n",
    "        if calculate_entropy:\n",
    "            name = participant_id\n",
    "            group = condition\n",
    "            for axis in axis3:             \n",
    "                local_name[name  + '_' + group + '_pos_' + axis + '_entropy'].append(SampEn(t[column_name + axis].values, m, r=0.2 * np.std(t[column_name + axis].values)))\n",
    "                local_name[name  + '_' + group + '_vel_' + axis + '_entropy'].append(SampEn(t['vel_' + axis].values, m, r=0.2 * np.std(t['vel_' + axis].values)))\n",
    "                local_name[name  + '_' + group + '_vel_' + axis + '_mean'].append(t['vel_' + axis].values.mean())\n",
    "                local_name[name  + '_' + group + '_acc_' + axis + '_mean'].append(t['acc_' + axis].values.mean())\n",
    "\n",
    "if calculate_entropy:\n",
    "    for name in participant_id_order:\n",
    "        for group in groups_order:\n",
    "            for axis in axis3:\n",
    "                np.save(path + name  + '_' + group + '_pos_' + axis + '_entropy',local_name[name  + '_' + group + '_pos_' + axis + '_entropy'])\n",
    "                np.save(path + name  + '_' + group + '_vel_' + axis + '_entropy',local_name[name  + '_' + group + '_vel_' + axis + '_entropy'])\n",
    "                np.save(path + name  + '_' + group + '_vel_' + axis + '_mean',local_name[name  + '_' + group + '_vel_' + axis + '_mean'])\n",
    "                np.save(path + name  + '_' + group + '_acc_' + axis + '_mean',local_name[name  + '_' + group + '_acc_' + axis + '_mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Print collision times, construct anova df, and plot 3D collision position ###\n",
    "print(len(human_like_collision))\n",
    "print(len(traditional_collision))\n",
    "human_like_df = pd.DataFrame(human_like_collision)\n",
    "human_like_df.columns=[\"X\",\"Y\",\"Z\"]\n",
    "human_like_df[\"condition\"] = \"human_like\"\n",
    "traditional_df = pd.DataFrame(traditional_collision)\n",
    "traditional_df.columns=[\"X\",\"Y\",\"Z\"]\n",
    "traditional_df[\"condition\"] = \"traditional\"\n",
    "valve_df = pd.DataFrame({'X': [-0.4878,0.0344,0.5996], 'Y':[0.3056,1.0998,0.4914], 'Z':[0.4008,0.2957,0.2871]})\n",
    "valve_df[\"condition\"] = \"valve\"\n",
    "total_df = pd.concat([human_like_df,traditional_df,valve_df],ignore_index=True)\n",
    "\n",
    "fig = px.scatter_3d(total_df, x='X', y='Y', z='Z',\n",
    "            color='condition',color_continuous_scale=px.colors.sequential.Viridis, opacity=0.8)\n",
    "fig.update_traces(marker_size = 3)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### plot 3D image of end-effector trajectory and collision point ###\n",
    "# NOTE: if there is no collision, it will show an error, especially for human like group #\n",
    "index = 5\n",
    "print(conditions[index])\n",
    "collision_array = []\n",
    "collision_group = data_raw[index].groupby(['ColX', 'ColY', 'ColZ'])\n",
    "for h,d in collision_group:\n",
    "    if (h[0] != 0.0):\n",
    "        # if not (d[[\"CollisionTarget\"]].values[0][0][0:4] == \"Miss\" and d[[\"CollisionJoint\"]].values[0][0][0:4] == \"node\"):\n",
    "        if d[[\"CollisionTarget\"]].values[0][0][0:4] != \"Miss\" and d[[\"CollisionTarget\"]].values[0][0][0:4] != \"Pipe\":\n",
    "            collision_array.append(h)\n",
    "collision_df = pd.DataFrame(collision_array)\n",
    "collision_df.columns=[\"X\",\"Y\",\"Z\"]\n",
    "collision_df[\"condition\"] = \"collision\"\n",
    "trajectory_df = data_raw[index][['Joint8X', 'Joint8Y', 'Joint8Z']]\n",
    "trajectory_df.columns=[\"X\",\"Y\",\"Z\"]\n",
    "trajectory_df[\"condition\"] = \"trajectory\"\n",
    "valve_df = pd.DataFrame({'X': [-0.4878,0.0344,0.5996], 'Y':[0.3056,1.0998,0.4914], 'Z':[0.4008,0.2957,0.2871]})\n",
    "valve_df[\"condition\"] = \"valve\"\n",
    "total_df = pd.concat([collision_df,trajectory_df,valve_df],ignore_index=True)\n",
    "\n",
    "fig = px.scatter_3d(total_df, x='X', y='Y', z='Z',\n",
    "            color='condition',color_continuous_scale=px.colors.sequential.Viridis, opacity=0.8)\n",
    "fig.update_traces(marker_size = 3)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### pair analysis visualization \n",
    "\n",
    "sns.set(style = 'whitegrid')\n",
    "x = 'conditions'\n",
    "y = 'collision_times' # Choose 'collision_times' or 'time'\n",
    "order = [ \"human_like\",\"traditional\"]\n",
    "method = 'Wilcoxon' #'Kruskal','Wilcoxon'\n",
    "\n",
    "fig, axes = plt.subplots(1,2, figsize=(12,6), dpi=100)\n",
    "\n",
    "if 1:\n",
    "   axes[0] = sns.boxplot(ax = axes[0], data=collision_statistics, x=x, y=y, order=order)\n",
    "   test_results = add_stat_annotation(ax=axes[0], data=collision_statistics, x=x, y=y, order=order,\n",
    "                                    box_pairs=[(order[0], order[1])],\n",
    "                                    test=method, \n",
    "                                    comparisons_correction=None, \n",
    "                                    text_format='star', loc='outside', verbose=1,\n",
    "                                 #    line_offset_to_box= -1,\n",
    "                                 #    line_offset= 1,\n",
    "                                 #    text_offset = -1,\n",
    "                                    # stats_params={'alternative': 'greater'}\n",
    "                                    )\n",
    "   axes[0].set(xlabel = method + ' analysis between groups', ylabel=y)\n",
    "\n",
    "y = 'time'\n",
    "if 1:\n",
    "   axes[1] = sns.boxplot(ax = axes[1],data=collision_statistics, x=x, y=y,order=order,\n",
    "                  # palette = 'mako',\n",
    "                  # linewidth=1.5,\n",
    "                  # errcolor=\"0.2\",errwidth =1.5,\n",
    "                  # edgecolor=\".2\",\n",
    "                  # facecolor=(1, 1, 1, 0)\n",
    "                  )\n",
    "   test_results = add_stat_annotation(ax=axes[1], data=collision_statistics, x=x, y=y,\n",
    "                                    box_pairs=[(order[0], order[1])],\n",
    "                                    test=method, \n",
    "                                    comparisons_correction=None, \n",
    "                                    text_format='star', loc='outside', verbose=1,\n",
    "                                 #    line_offset_to_box= -0.5,\n",
    "                                 #    line_offset= -0.5,\n",
    "                                    #   stats_params={'alternative': 'greater'}\n",
    "                                    )\n",
    "   axes[1].set(xlabel = method + ' analysis between groups', ylabel=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### pair analysis visualization start end\n",
    "sns.set(style = 'whitegrid')\n",
    "x = 'conditions'\n",
    "y = 'collision_times' # 'collision_times', 'time'\n",
    "hue = 'trail'\n",
    "order = [\"traditional\",\"human_like\"]\n",
    "trail_states = [\"01\",\"02\",\"03\",\"04\",\"05\",\"06\",\"07\",\"08\",\"09\",\"10\"]\n",
    "method = 'Kruskal'\n",
    "state = 1\n",
    "\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1,2, figsize=(12,6), dpi=100)\n",
    "if 1:\n",
    "   axes[0] = sns.boxplot(ax = axes[0], data=collision_statistics, x=x, y=y, hue=hue)\n",
    "   test_results = add_stat_annotation(ax=axes[0], data=collision_statistics, x=x, y=y, hue=hue,\n",
    "                                    box_pairs=[\n",
    "                                       ((order[1], trail_states[0]), (order[1], trail_states[1])),\n",
    "                                       ((order[1], trail_states[0]), (order[1], trail_states[9])),\n",
    "                                       ((order[0], trail_states[0]), (order[0], trail_states[1])),\n",
    "                                       ((order[0], trail_states[0]), (order[0], trail_states[9])),\n",
    "                                       ],\n",
    "                                    test=method, \n",
    "                                    comparisons_correction=None, \n",
    "                                    text_format='star', loc='outside', verbose=1,\n",
    "                                 #    line_offset_to_box= -1,\n",
    "                                 #    line_offset= 1,\n",
    "                                 #    text_offset = -1,\n",
    "                                    # stats_params={'alternative': 'greater'}\n",
    "                                    )\n",
    "   axes[0].set(xlabel = method + ' analysis between groups', ylabel=y)\n",
    "   axes[0].legend_.remove()\n",
    "\n",
    "y='time'\n",
    "if 1:\n",
    "   axes[1] = sns.boxplot(ax = axes[1], data=collision_statistics, x=x, y=y, hue=hue)\n",
    "   test_results = add_stat_annotation(ax=axes[1], data=collision_statistics, x=x, y=y, hue=hue,\n",
    "                                    box_pairs=[\n",
    "                                       ((order[1], trail_states[0]), (order[1], trail_states[1])),\n",
    "                                       ((order[1], trail_states[0]), (order[1], trail_states[9])),\n",
    "                                       ((order[0], trail_states[0]), (order[0], trail_states[1])),\n",
    "                                       ((order[0], trail_states[0]), (order[0], trail_states[9])),\n",
    "                                       ],\n",
    "                                    test=method, \n",
    "                                    comparisons_correction=None, \n",
    "                                    text_format='star', loc='outside', verbose=1,\n",
    "                                 #    line_offset_to_box= -1,\n",
    "                                 #    line_offset= 1,\n",
    "                                 #    text_offset = -1,\n",
    "                                    # stats_params={'alternative': 'greater'}\n",
    "                                    )\n",
    "   axes[1].set(xlabel = method + ' analysis between groups', ylabel=y)\n",
    "   plt.legend(bbox_to_anchor=(1.02, 1), loc='upper left', borderaxespad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build statistical df for entropy\n",
    "names = [\"01\",\"02\",\"03\",\"04\",\"05\",\"06\",\"07\",\"08\",\"09\",\"10\"]\n",
    "axis3 = ['X','Y','Z']\n",
    "groups = [\"traditional\",\"human_like\"]\n",
    "\n",
    "total_df = pd.DataFrame()\n",
    "for name in names:\n",
    "    local_name[name+'_total_df'] = pd.DataFrame()\n",
    "    local_name[name + '_dict'] = {}\n",
    "    for group in groups:\n",
    "        local_name[name  + '_' + group + '_df'] = pd.DataFrame()\n",
    "        for axis in axis3:\n",
    "            local_name[name  + '_' + group + '_pos_' + axis + '_entropy'] = np.load(path + name  + '_' + group + '_pos_' + axis + '_entropy.npy')\n",
    "            local_name[name  + '_' + group + '_vel_' + axis + '_entropy'] = np.load(path + name  + '_' + group + '_vel_' + axis + '_entropy.npy')\n",
    "            local_name[name  + '_' + group + '_vel_' + axis + '_mean'] = np.load(path + name  + '_' + group + '_vel_' + axis + '_mean.npy')\n",
    "\n",
    "            local_name[name  + '_' + group + '_df']['entropy_pos_' + axis] = local_name[name  + '_' + group + '_pos_' + axis + '_entropy']\n",
    "            local_name[name  + '_' + group + '_df']['entropy_vel_' + axis] = local_name[name  + '_' + group + '_vel_' + axis + '_entropy']\n",
    "            local_name[name  + '_' + group + '_df']['mean_vel_' + axis] = local_name[name  + '_' + group + '_vel_' + axis + '_mean']\n",
    "\n",
    "            local_name[name + '_dict'][name  + '_' + group + '_pos_' + axis + '_entropy'] = local_name[name  + '_' + group + '_pos_' + axis + '_entropy']\n",
    "            local_name[name + '_dict'][name  + '_' + group + '_vel_' + axis + '_entropy'] = local_name[name  + '_' + group + '_vel_' + axis + '_entropy']\n",
    "            local_name[name + '_dict'][name  + '_' + group + '_vel_' + axis + '_mean'] = local_name[name  + '_' + group + '_vel_' + axis + '_mean']\n",
    "        local_name[name  + '_' + group + '_df'][\"Groups\"] = group\n",
    "        local_name[name+'_total_df'] = pd.concat([local_name[name+'_total_df'],local_name[name  + '_' + group + '_df']],ignore_index=True)\n",
    "    local_name[name+'_total_df'].to_csv((path + name + \"_combine.csv\"))\n",
    "    entropy_df = pd.DataFrame.from_dict(local_name[name + '_dict'],orient='index')\n",
    "    entropy_df = entropy_df.transpose()\n",
    "    entropy_df.to_csv(path + name + \"_entropy.csv\")\n",
    "    total_df = total_df.append(local_name[name+'_total_df'])\n",
    "total_df.to_csv(path + \"Total_entropy.csv\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function of entropy anova (Not test yet) ###\n",
    "def vel_entropy_anova(data,name):\n",
    "   for analysis_metrics in ['mean','entropy']:\n",
    "      for axis in ['X','Y','Z']:\n",
    "         sns.set(style = 'whitegrid')\n",
    "         x = 'Groups'\n",
    "         y = analysis_metrics + '_vel_' + axis\n",
    "\n",
    "         order = [\"traditional\",\"human_like\"]\n",
    "         method = 'Kruskal'\n",
    "\n",
    "         fig, axes = plt.subplots(1,2, figsize=(12,6), dpi=100)\n",
    "         if 1:\n",
    "            axes[0] = sns.boxplot(ax = axes[0], data=data, x=x, y=y, order=order)\n",
    "            test_results = add_stat_annotation(ax=axes[0], data=data, x=x, y=y, order=order,\n",
    "                                             box_pairs=[\n",
    "                                                (order[0], order[1]),\n",
    "                                                ],\n",
    "                                             test=method, \n",
    "                                             comparisons_correction=None, \n",
    "                                             text_format='star', loc='outside', verbose=1,\n",
    "                                             )\n",
    "            axes[0].set(xlabel = method + ' analysis between groups', ylabel=name + '_' + y)\n",
    "            # axes[0].legend_.remove()\n",
    "         if 0:\n",
    "            axes[1] = sns.boxplot(ax = axes[1], data=data, x=x, y=y, order=order)\n",
    "            test_results = add_stat_annotation(ax=axes[1], data=data, x=x, y=y, order=order,\n",
    "                                             box_pairs=[\n",
    "                                                (order[1], order[2]),\n",
    "                                                (order[1], order[3]),\n",
    "                                                (order[2], order[3])\n",
    "                                                ],\n",
    "                                             test=method, \n",
    "                                             comparisons_correction=None, \n",
    "                                             text_format='star', loc='outside', verbose=1,\n",
    "                                             )\n",
    "            axes[1].set(xlabel = method + ' analysis between groups', ylabel=name + '_' + y)\n",
    "            plt.legend(bbox_to_anchor=(1.02, 1), loc='upper left', borderaxespad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/process/'\n",
    "object_names = [\"01\",\"02\",\"03\",\"04\",\"05\",\"06\",\"07\",\"08\",\"09\",\"10\"]\n",
    "for name in object_names:\n",
    "    data = pd.read_csv(path + name + '_combine.csv')\n",
    "    data.drop(['Unnamed: 0'],axis=1,inplace=True)\n",
    "    vel_entropy_anova(data,name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "08b67431c17cfbaf5d75b8f833cc91109bdedee36e8bc657eba4f68a2229c720"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
